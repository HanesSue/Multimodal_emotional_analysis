import os
import tempfile
from sklearn.metrics import accuracy_score, f1_score, mean_squared_error
import torch
import numpy as np
import pickle
import torch.nn as nn
from torch.utils.data import Dataset
from torchvision import transforms
from tqdm import tqdm
from utils.SIMSData import SIMSData
import math
from collections import Counter
from torch.utils.data import DataLoader, WeightedRandomSampler
from utils.VideosProcessor import VideosProcessor
class SIMSVideoDataset(Dataset):
    def __init__(self, sims_data, feature_dict, transform=None, num_frames=144):
        """
        å‚æ•°:
            sims_data: SIMSDataå®ä¾‹ï¼ŒåŒ…å«è§†é¢‘è·¯å¾„å’Œæ ‡ç­¾
            feature_dict: ä»pklæ–‡ä»¶åŠ è½½çš„ç‰¹å¾å­—å…¸ï¼Œkeyä¸º"video_id_clip_id"
            transform: å›¾åƒé¢„å¤„ç†è½¬æ¢
            num_frames: æ¯ä¸ªè§†é¢‘é‡‡æ ·çš„å¸§æ•°
        """
        self.sims_data = sims_data
        self.feature_dict = feature_dict
        self.num_frames = num_frames

    def __len__(self):
        return len(self.sims_data)

    def __getitem__(self, idx):
        video_info, _, labels = self.sims_data[idx]  # video_info æ˜¯æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
    
        # è§£æ video_id å’Œ clip_id
        filename_with_ext = os.path.basename(video_info)
        clip_id = os.path.splitext(filename_with_ext)[0]
        parent_dir = os.path.dirname(video_info)
        video_id = os.path.basename(parent_dir)


        # è·å–ç‰¹å¾å‘é‡
        # æ„å»ºç‰¹å¾å­—å…¸ä¸­çš„é”®
        feature_key = f"{video_id}_{clip_id}"
        
        # è·å–å¯¹åº”çš„ç‰¹å¾å‘é‡
        if feature_key in self.feature_dict:
            features = self.feature_dict[feature_key]['vision']
        else:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°ç‰¹å¾å‘é‡ for {feature_key}")
            # è¿”å›å…¨é›¶ç‰¹å¾æˆ–æŠ›å‡ºå¼‚å¸¸ï¼Œå–å†³äºæ‚¨çš„å¤„ç†é€»è¾‘
            features = np.zeros((self.num_frames, 35))  # å‡è®¾ç‰¹å¾ç»´åº¦ä¸º709
        
        # ç‰¹å¾é‡‡æ ·ï¼ˆå¦‚æœå¸§æ•°è¶…è¿‡num_framesï¼‰
        if len(features) > self.num_frames:
            # å‡åŒ€é‡‡æ ·å¸§
            indices = np.linspace(0, len(features)-1, self.num_frames, dtype=int)
            features = features[indices]
        elif len(features) < self.num_frames:
            # ä¸è¶³åˆ™å¡«å……é›¶å¸§
            pad_len = self.num_frames - len(features)
            features = np.pad(features, ((0, pad_len), (0, 0)), mode='constant')
        
        # è½¬æ¢ä¸ºå¼ é‡
        features = torch.tensor(features, dtype=torch.float32)
        
        # è·å–æƒ…æ„Ÿæ ‡ç­¾
        label_V = torch.tensor(labels[3], dtype=torch.float)  # valenceç»´åº¦
        
        return features, label_V

class SpecialSomoothL1Loss(nn.Module):
    def __init__(self):
        super().__init__()
        
    def forward(self, prediction, target):
        error = torch.abs(prediction - target)
        loss = torch.zeros_like(error)
        # åŒºé—´ä¸€ï¼šï¼ˆ0 â‰¤ error < 0.4ï¼‰
        cond_f = error < 0.4
        loss[cond_f] = 1.25 * error[cond_f].pow(2)

        # åŒºé—´äºŒï¼šï¼ˆ0.4 â‰¤ error < 1.0ï¼‰
        cond_g = (error >= 0.4) & (error < 1.0)
        loss[cond_g] = error[cond_g] - 0.2

        # åŒºé—´ä¸‰ï¼šï¼ˆerror â‰¥ 1.0ï¼‰ï¼Œä¸å¸Œæœ›ä¸º 0ï¼Œå¦åˆ™æç«¯è¯¯å·®æ²¡æœ‰æƒ©ç½š
        cond_h = error >= 1.0
        loss[cond_h] = error[cond_h] - 0.2   # æˆ–è€…ä½ æƒ³è¦æ›´å¤§çš„æƒ©ç½šï¼Œæ¯”å¦‚ error[cond_h] - 0.2 + (error[cond_h] - 1.0)

        return loss.mean()


class VideoExtractor:
    """
    è§†é¢‘æƒ…æ„Ÿåˆ†æå™¨ï¼š
    å‚æ•° type:   "train" (è®­ç»ƒæ–°çš„æ¨¡å‹)  "load" (åŠ è½½å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹)
    """
    def __init__(self, type="train", details=True, **kwargs):
        self.type = type
        self.details = details
        self.DEVICE = kwargs.get("device", torch.device("cuda" if torch.cuda.is_available() else "cpu"))
        self.NUM_FRAMES = kwargs.get("num_frames", 144)
        self.BATCH_SIZE = kwargs.get("batch_size", 64)
        self.EPOCHS = kwargs.get("epochs", 40)
        self.PATIENCE = kwargs.get("patience", 10)
        self.LEARNING_RATE = kwargs.get("learning_rate", 1e-3)
        self.MODEL_NAME = kwargs.get("model_name", "emotion_regressor")
        self.MODEL_DIR = kwargs.get("model_dir", "saved_model")
        self.MODEL_SAVE_PATH = os.path.join(self.MODEL_DIR, f"{self.MODEL_NAME}.pth")
        self.DATA_ROOT = kwargs.get("data_root", "data/ch-sims2s/ch-simsv2s")
        self.PKL_ROOT = kwargs.get("pkl_root", "data/ch-sims2s")
        self.LR_SCHEDULER_FACTOR = kwargs.get("lr_scheduler_factor", 0.5)
        self.LR_SCHEDULER_PATIENCE = kwargs.get("lr_scheduler_patience", 5)
        # æ ‡ç­¾é…ç½®
        self.DISCRETE_VALUES = [
            -1, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1
        ]  # ç¦»æ•£åŒ–æ ‡ç­¾  

        # åˆ›å»ºæ¨¡å‹ç›®å½•
        os.makedirs(self.MODEL_DIR, exist_ok=True)
        
        if details:
            print("æ­£åœ¨åˆå§‹åŒ–è§†é¢‘æƒ…æ„Ÿåˆ†æå™¨...")
        
        # åŠ è½½OpenFaceç‰¹å¾
        self.load_openface_features()
        
        # åˆå§‹åŒ–æ•°æ®é›†
        self.init_datasets()
        
        # æ ¹æ®ç±»å‹åˆå§‹åŒ–æ¨¡å‹
        if self.type == "train":
            self.init_model_for_training()
        elif self.type == "load":
            self.load_trained_model()
        else:
            raise ValueError("typeå‚æ•°å¿…é¡»ä¸º'train'æˆ–'load'")
    
    def load_openface_features(self):
        """åŠ è½½OpenFaceæå–çš„é¢éƒ¨ç‰¹å¾"""
        try:
            pkl_path = os.path.join(self.PKL_ROOT, "openface_features_AU.pkl")
            with open(pkl_path, "rb") as f:
                data = pickle.load(f)
                self.features_dict = data["videos"]
                print(f"âœ… æˆåŠŸåŠ è½½{len(self.features_dict)}ä¸ªè§†é¢‘çš„ç‰¹å¾")
        except Exception as e:
            print(f"âŒ åŠ è½½ç‰¹å¾å¤±è´¥: {e}")
            self.features_dict = {}
    
    def init_datasets(self):
        """åˆå§‹åŒ–è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ï¼ˆå«åˆ†æ¡¶çº§åˆ«å‡è¡¡é‡‡æ ·ï¼‰"""
        if self.details:
            print("æ­£åœ¨åˆå§‹åŒ–æ•°æ®é›†...")

        # 1. åŠ è½½åŸå§‹æ•°æ®
        self.train_raw = SIMSData(root=self.DATA_ROOT, mode="train")
        self.valid_raw = SIMSData(root=self.DATA_ROOT, mode="valid")
        self.test_raw  = SIMSData(root=self.DATA_ROOT, mode="test")

        # 2. åˆ›å»ºè§†é¢‘ç‰¹å¾æ•°æ®é›†
        self.train_dataset = SIMSVideoDataset(
            self.train_raw,
            self.features_dict,
            num_frames=self.NUM_FRAMES
        )
        self.valid_dataset = SIMSVideoDataset(
            self.valid_raw,
            self.features_dict,
            num_frames=self.NUM_FRAMES
        )
        self.test_dataset  = SIMSVideoDataset(
            self.test_raw,
            self.features_dict,
            num_frames=self.NUM_FRAMES
        )

        # 3. ç»Ÿè®¡è®­ç»ƒé›†æ¯æ¡æ ·æœ¬çš„ç¦»æ•£æ ‡ç­¾ï¼ˆlabel_Vï¼‰ä»¥åŠå„æ ‡ç­¾çš„è®¡æ•°
        #    SIMSVideoDataset çš„ __getitem__ è¿”å› (features, label_V)ï¼Œå…¶ä¸­ label_V æ˜¯ä¸€ä¸ª 0-11 ä¹‹é—´çš„ç¦»æ•£å€¼
        all_labels = []
        for i in range(len(self.train_dataset)):
            _, label_V = self.train_dataset[i]  # è¿™é‡Œ label_V æ˜¯ä¸€ä¸ª Tensor
            raw_val = label_V.item()                    # ä» Tensor é‡Œå–å‡º Python float
            disc_val = self.discretize(raw_val)         # ä¼ å…¥ floatï¼Œè€Œä¸æ˜¯ Tensor
            all_labels.append(disc_val)

        # ç»Ÿè®¡æ¯ä¸ª label_V å‡ºç°çš„æ¬¡æ•°
        counter = Counter(all_labels)
        class_to_weight = {}
        for val in self.DISCRETE_VALUES:
            # å¦‚æœæŸä¸ªå€¼åœ¨ counter é‡Œä¸å­˜åœ¨ï¼ˆcount=0ï¼‰ï¼Œä¹Ÿç»™ä¸€ä¸ªå¾ˆå°çš„ weight é˜²æ­¢é™¤ 0
            count_val = counter.get(val, 0)
            class_to_weight[val] = 1.0 / (count_val + 1e-6)

        # 5. ä¸ºè®­ç»ƒé›†ä¸­æ¯æ¡æ ·æœ¬åˆ†é…â€œå¯¹åº”æ ‡ç­¾çš„æƒé‡â€
        sample_weights = [ class_to_weight[label] for label in all_labels ]  # é•¿åº¦ = len(train_dataset)
        # 6. ç”¨ sample_weights åˆ›å»º WeightedRandomSampler
        sampler = WeightedRandomSampler(
            weights=sample_weights,               # æ¯æ¡æ ·æœ¬çš„é‡‡æ ·æƒé‡åˆ—è¡¨
            num_samples=len(sample_weights),      # æ¯ä¸ª epoch æŠ½å–æ ·æœ¬æ€»æ•°ï¼Œå¯ä»¥è®¾ç½®ä¸º len(sample_weights)
            replacement=True                      # æœ‰æ”¾å›æŠ½æ ·
        )

        # 7. ç”¨è¿™ä¸ª sampler æ›¿æ¢åŸæ¥çš„ shuffle=Trueï¼Œåˆ›å»º train_loader
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.BATCH_SIZE,
            sampler=sampler,       
            num_workers=0,
            pin_memory=True
        )

        # éªŒè¯é›†å’Œæµ‹è¯•é›†ä»æŒ‰åŸå…ˆæ–¹å¼ï¼ˆä¸åšå‡è¡¡é‡‡æ ·ï¼‰
        self.valid_loader = DataLoader(
            self.valid_dataset,
            batch_size=self.BATCH_SIZE,
            shuffle=False,
            num_workers=0,
            pin_memory=True
        )
        self.test_loader = DataLoader(
            self.test_dataset,
            batch_size=self.BATCH_SIZE,
            shuffle=False,
            num_workers=0,
            pin_memory=True
        )

        if self.details:
            print(f"è®­ç»ƒé›†: {len(self.train_dataset)} samples")
            print (f"è®­ç»ƒé›†åˆ†å¸ƒ: {counter}")
            print( f"è®­ç»ƒé›†æƒé‡: {class_to_weight}")
            print(f"éªŒè¯é›†: {len(self.valid_dataset)} samples")
            print(f"æµ‹è¯•é›†: {len(self.test_dataset)} samples")
    def init_model_for_training(self):
        """åˆå§‹åŒ–ç”¨äºè®­ç»ƒçš„æ¨¡å‹"""
        self.model = self._create_model()
        self.model.to(self.DEVICE)
        
        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        #self.criterion = nn.MSELoss()
        self.criterion = SpecialSomoothL1Loss()
        self.optimizer = torch.optim.Adam(
            self.model.parameters(), 
            lr=self.LEARNING_RATE
        )
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',          # ç›‘æ§éªŒè¯æŸå¤±ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
            factor=self.LR_SCHEDULER_FACTOR,  # å­¦ä¹ ç‡è¡°å‡å› å­ï¼ˆå¦‚0.5è¡¨ç¤ºå‡åŠï¼‰
            patience=self.LR_SCHEDULER_PATIENCE,  # è¿ç»­å¤šå°‘ä¸ªepochæœªæ”¹å–„åˆ™è¡°å‡å­¦ä¹ ç‡
            verbose=True,       # æ‰“å°å­¦ä¹ ç‡è°ƒæ•´ä¿¡æ¯
            min_lr=1e-7         # æœ€å°å­¦ä¹ ç‡ï¼Œé˜²æ­¢å­¦ä¹ ç‡è¿‡ä½
        )
        
        if self.details:
            print("æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡è®­ç»ƒ...")
            print(f"å­¦ä¹ ç‡è°ƒåº¦å™¨å·²è®¾ç½®ï¼šæ¯{self.LR_SCHEDULER_PATIENCE}ä¸ªepochæœªæ”¹å–„åˆ™è¡°å‡è‡³{self.LR_SCHEDULER_FACTOR}å€")
    
    def _create_model(self):
        """åˆ›å»ºè§†é¢‘æƒ…æ„Ÿå›å½’æ¨¡å‹"""    
        class EmotionRegressor(nn.Module):
            def __init__(self, input_dim=35, hidden_dim=128):
                super(EmotionRegressor, self).__init__()
                
                # ç‰¹å¾æå–å±‚
                self.feature_extractor = nn.Sequential(
                    nn.Linear(input_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(0.5)
                )
                
                # æ—¶åºå»ºæ¨¡
                self.lstm = nn.LSTM(
                    input_size=hidden_dim,
                    hidden_size=hidden_dim,
                    num_layers=2,
                    batch_first=True,
                    bidirectional=True,
                    dropout=0.3
                )
                
                # å›å½’è¾“å‡ºå±‚
                self.regressor = nn.Sequential(
                    nn.Linear(hidden_dim * 2, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(hidden_dim, 1)  # é¢„æµ‹valenceå€¼
                )
            
            def forward(self, x):
                batch_size = x.size(0)
                
                # ç‰¹å¾æå–
                x = self.feature_extractor(x)
                
                # LSTMå¤„ç†æ—¶åºä¿¡æ¯
                lstm_out, _ = self.lstm(x)
                
                # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
                last_output = lstm_out[:, -1, :]
                
                # å›å½’é¢„æµ‹
                output = self.regressor(last_output)
                
                return output
        class TransformerRegressor(nn.Module):
            def __init__(self, input_dim=35, d_model=256, nhead=4, num_layers=3, dropout=0.3):
                super(TransformerRegressor, self).__init__()

                # ç¬¬1æ­¥ï¼šå°†åŸå§‹ç‰¹å¾æŠ•åˆ° d_model ç»´åº¦
                self.input_fc = nn.Linear(input_dim, d_model)

                # Transformer EncoderLayerï¼Œå †å  num_layers ä¸ª
                encoder_layer = nn.TransformerEncoderLayer(
                    d_model=d_model,
                    nhead=nhead,
                    dim_feedforward=d_model * 4,
                    dropout=dropout,
                    activation='relu',
                    batch_first=True   # ç›´æ¥ä½¿ç”¨ [B, T, d_model]
                )
                self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

                # å›å½’è¾“å‡ºï¼šå…ˆåšå¹³å‡æ± åŒ–ï¼Œå†å…¨è¿æ¥
                self.output_fc = nn.Sequential(
                    nn.Linear(d_model, d_model // 2),
                    nn.ReLU(),
                    nn.Dropout(dropout),
                    nn.Linear(d_model // 2, 1)
                )

            def forward(self, x):
                """
                x: [B, T, input_dim]
                """
                # 1) æŠ•åˆ° Transformer æ‰€éœ€ç»´åº¦
                x_proj = self.input_fc(x)  # [B, T, d_model]

                # 2) ä¸€èˆ¬ä¸åš position encodingï¼ˆå› ä¸º T æ¯”è¾ƒå°ï¼‰ï¼Œä¹Ÿå¯ä»¥åŠ  learnable PE
                #    è¿™é‡Œç›´æ¥å¥—ç”¨åŸå§‹ x_proj
                #    transformer expects [B, T, d_model] if batch_first=True
                out = self.transformer(x_proj)  # [B, T, d_model]

                # 3) å¯¹æ—¶é—´ç»´åº¦åšå¹³å‡æ± åŒ–
                pooled = out.mean(dim=1)       # [B, d_model]

                # 4) å›å½’è¾“å‡º
                output = self.output_fc(pooled)  # [B, 1]
                return output
        class PositionalEncoding(nn.Module):
            """æ ‡å‡†çš„æ­£å¼¦/ä½™å¼¦ä½ç½®ç¼–ç ï¼Œç”¨äºç»™ Transformer æä¾›æ—¶åºä¿¡æ¯ã€‚"""
            def __init__(self, d_model, max_len=5000):
                super().__init__()
                # pe: [1, max_len, d_model]
                pe = torch.zeros(max_len, d_model)
                position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # [max_len, 1]
                div_term = torch.exp(
                    torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model)
                )  # [d_model/2]
                pe[:, 0::2] = torch.sin(position * div_term)
                pe[:, 1::2] = torch.cos(position * div_term)
                pe = pe.unsqueeze(0)  # [1, max_len, d_model]
                self.register_buffer("pe", pe)

            def forward(self, x: torch.Tensor) -> torch.Tensor:
                """
                Args:
                    x: [B, T, d_model]
                Returns:
                    x + pe[:, :T, :]ï¼Œå½¢çŠ¶ä¸å˜
                """
                seq_len = x.size(1)
                return x + self.pe[:, :seq_len, :]
        class WithBiasConvTransformerRegressor(nn.Module):
            """
            å…ˆç”¨ 1D å·ç§¯åœ¨æ—¶é—´ç»´åº¦ä¸Šåšå±€éƒ¨ç‰¹å¾æå–ï¼Œå†æŠŠå·ç§¯è¾“å‡ºåºåˆ—å–‚ç»™ TransformerEncoderï¼Œ
            æœ€ååšå¹³å‡æ± åŒ–æ¥å…¨è¿æ¥å›å½’è¾“å‡ºå•ä¸€è¿ç»­å€¼ï¼ˆvalenceï¼‰ã€‚
            """
            def __init__(
                self,
                input_dim: int = 35,
                conv_channels: int = 64,
                conv_kernel: int = 3,
                d_model: int = 128,
                nhead: int = 4,
                num_layers: int = 2,
                dropout: float = 0.3,
            ):
                super().__init__()
                # ---------------------------------------------------------
                # ç¬¬ä¸€é˜¶æ®µï¼š1D å·ç§¯
                #   è¾“å…¥: [B, T, input_dim] â†’ permute â†’ [B, input_dim, T]
                #   è¾“å‡º: [B, conv_channels, T] â†’ permute â†’ [B, T, conv_channels]
                # ---------------------------------------------------------
                padding = conv_kernel // 2  # ä¿è¯è¾“å‡ºæ—¶åºé•¿åº¦å’Œè¾“å…¥ç›¸åŒ
                self.conv_block = nn.Sequential(
                    nn.Conv1d(in_channels=input_dim, out_channels=conv_channels,
                            kernel_size=conv_kernel, padding=padding),
                    nn.BatchNorm1d(conv_channels),
                    nn.ReLU(inplace=True),
                    nn.Dropout(dropout),

                    # ä½ å¯ä»¥è‡ªè¡Œå åŠ æ›´å¤š Conv1d å±‚ï¼š
                    # nn.Conv1d(conv_channels, conv_channels, kernel_size=conv_kernel, padding=padding),
                    # nn.BatchNorm1d(conv_channels),
                    # nn.ReLU(inplace=True),
                    # nn.Dropout(dropout),
                )

                # ---------------------------------------------------------
                # ç¬¬äºŒé˜¶æ®µï¼šTransformer Encoder
                #   è¾“å…¥: [B, T, conv_channels] â†’ å…ˆçº¿æ€§æŠ•åˆ° d_model â†’ æ·»åŠ ä½ç½®ç¼–ç  â†’ Transformer
                #   è¾“å‡º: [B, T, d_model]
                # ---------------------------------------------------------
                self.input_fc = nn.Linear(conv_channels, d_model)
                self.pos_enc = PositionalEncoding(d_model)

                encoder_layer = nn.TransformerEncoderLayer(
                    d_model=d_model,
                    nhead=nhead,
                    dim_feedforward=d_model * 4,
                    dropout=dropout,
                    activation="relu",
                    batch_first=True,  # è®©è¾“å…¥ä¸º [B, T, d_model]
                )
                self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

                # ---------------------------------------------------------
                # ç¬¬ä¸‰é˜¶æ®µï¼šå›å½’è¾“å‡ºå±‚
                #   å¯¹ Transformer è¾“å‡ºåœ¨æ—¶é—´ç»´åº¦åšå¹³å‡æ± åŒ– â†’ [B, d_model] â†’ å…¨è¿æ¥ â†’ å•å€¼å›å½’
                # ---------------------------------------------------------

                self.norm = nn.LayerNorm(d_model) 
                self.regressor = nn.Sequential(
                    nn.Linear(d_model, d_model // 2),
                    nn.ReLU(inplace=True),
                    nn.Dropout(dropout),
                    nn.Linear(d_model // 2, 1),  # é¢„æµ‹ valence
                )
                # **æ–°å¢ä¸€ä¸ªåç½®å‚æ•°ï¼ˆæ ‡é‡ï¼‰**
                self.output_bias = nn.Parameter(torch.zeros(1))  # åˆå§‹åŒ–ä¸º 0

            def forward(self, x: torch.Tensor) -> torch.Tensor:
                """
                Args:
                    x: [B, T, input_dim]ï¼Œinput_dim=35
                Returns:
                    output: [B]ï¼ˆé¢„æµ‹çš„è¿ç»­ valence å€¼ï¼Œåé¢å¯ .squeeze()ï¼‰
                """
                # 1) 1D å·ç§¯é˜¶æ®µ
                # x åŸæœ¬ [B, T, input_dim]ï¼ŒConv1d éœ€è¦ [B, C_in, T] â†’ permute
                x_conv = x.permute(0, 2, 1)       # [B, input_dim, T]
                c = self.conv_block(x_conv)      # [B, conv_channels, T]
                c = c.permute(0, 2, 1)            # [B, T, conv_channels]

                # 2) çº¿æ€§æŠ•åˆ° d_model + ä½ç½®ç¼–ç 
                c_proj = self.input_fc(c)        # [B, T, d_model]
                c_pe   = self.pos_enc(c_proj)    # [B, T, d_model]

                # 3) Transformer Encoder
                out = self.transformer(c_pe)     # [B, T, d_model]

                # 4) æ—¶é—´ç»´åº¦å¹³å‡æ± åŒ–
                pooled = out.mean(dim=1)         # [B, d_model]

                # 5) å›å½’è¾“å‡º
                cont_pred = self.regressor(pooled).squeeze(-1)  # [B]
                # åœ¨æ ‡å‡†åŒ–ç©ºé—´é‡ŒåŠ ä¸Š bias
                cont_pred = cont_pred + self.output_bias       # [B]
                return cont_pred          # [B]    
        class ConvTransformerRegressor(nn.Module):
            """
            å…ˆç”¨ 1D å·ç§¯åœ¨æ—¶é—´ç»´åº¦ä¸Šåšå±€éƒ¨ç‰¹å¾æå–ï¼Œå†æŠŠå·ç§¯è¾“å‡ºåºåˆ—å–‚ç»™ TransformerEncoderï¼Œ
            æœ€ååšå¹³å‡æ± åŒ–æ¥å…¨è¿æ¥å›å½’è¾“å‡ºå•ä¸€è¿ç»­å€¼ï¼ˆvalenceï¼‰ã€‚
            """
            def __init__(
                self,
                input_dim: int = 35,
                conv_channels: int = 64,
                conv_kernel: int = 3,
                d_model: int = 128,
                nhead: int = 4,
                num_layers: int = 2,
                dropout: float = 0.3,
            ):
                super().__init__()
                # ---------------------------------------------------------
                # ç¬¬ä¸€é˜¶æ®µï¼š1D å·ç§¯
                #   è¾“å…¥: [B, T, input_dim] â†’ permute â†’ [B, input_dim, T]
                #   è¾“å‡º: [B, conv_channels, T] â†’ permute â†’ [B, T, conv_channels]
                # ---------------------------------------------------------
                padding = conv_kernel // 2  # ä¿è¯è¾“å‡ºæ—¶åºé•¿åº¦å’Œè¾“å…¥ç›¸åŒ
                self.conv_block = nn.Sequential(
                    nn.Conv1d(in_channels=input_dim, out_channels=conv_channels,
                            kernel_size=conv_kernel, padding=padding),
                    nn.BatchNorm1d(conv_channels),
                    nn.ReLU(inplace=True),
                    nn.Dropout(dropout),

                    # ä½ å¯ä»¥è‡ªè¡Œå åŠ æ›´å¤š Conv1d å±‚ï¼š
                    # nn.Conv1d(conv_channels, conv_channels, kernel_size=conv_kernel, padding=padding),
                    # nn.BatchNorm1d(conv_channels),
                    # nn.ReLU(inplace=True),
                    # nn.Dropout(dropout),
                )

                # ---------------------------------------------------------
                # ç¬¬äºŒé˜¶æ®µï¼šTransformer Encoder
                #   è¾“å…¥: [B, T, conv_channels] â†’ å…ˆçº¿æ€§æŠ•åˆ° d_model â†’ æ·»åŠ ä½ç½®ç¼–ç  â†’ Transformer
                #   è¾“å‡º: [B, T, d_model]
                # ---------------------------------------------------------
                self.input_fc = nn.Linear(conv_channels, d_model)
                self.pos_enc = PositionalEncoding(d_model)

                encoder_layer = nn.TransformerEncoderLayer(
                    d_model=d_model,
                    nhead=nhead,
                    dim_feedforward=d_model * 4,
                    dropout=dropout,
                    activation="relu",
                    batch_first=True,  # è®©è¾“å…¥ä¸º [B, T, d_model]
                )
                self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

                # ---------------------------------------------------------
                # ç¬¬ä¸‰é˜¶æ®µï¼šå›å½’è¾“å‡ºå±‚
                #   å¯¹ Transformer è¾“å‡ºåœ¨æ—¶é—´ç»´åº¦åšå¹³å‡æ± åŒ– â†’ [B, d_model] â†’ å…¨è¿æ¥ â†’ å•å€¼å›å½’
                # ---------------------------------------------------------
                self.regressor = nn.Sequential(
                    nn.Linear(d_model, d_model // 2),
                    nn.ReLU(inplace=True),
                    nn.Dropout(dropout),
                    nn.Linear(d_model // 2, 1),  # é¢„æµ‹ valence
                )

            def forward(self, x: torch.Tensor) -> torch.Tensor:
                """
                Args:
                    x: [B, T, input_dim]ï¼Œinput_dim=35
                Returns:
                    output: [B]ï¼ˆé¢„æµ‹çš„è¿ç»­ valence å€¼ï¼Œåé¢å¯ .squeeze()ï¼‰
                """
                # 1) 1D å·ç§¯é˜¶æ®µ
                # x åŸæœ¬ [B, T, input_dim]ï¼ŒConv1d éœ€è¦ [B, C_in, T] â†’ permute
                x_conv = x.permute(0, 2, 1)       # [B, input_dim, T]
                c = self.conv_block(x_conv)      # [B, conv_channels, T]
                c = c.permute(0, 2, 1)            # [B, T, conv_channels]

                # 2) çº¿æ€§æŠ•åˆ° d_model + ä½ç½®ç¼–ç 
                c_proj = self.input_fc(c)        # [B, T, d_model]
                c_pe   = self.pos_enc(c_proj)    # [B, T, d_model]

                # 3) Transformer Encoder
                out = self.transformer(c_pe)     # [B, T, d_model]

                # 4) æ—¶é—´ç»´åº¦å¹³å‡æ± åŒ–
                pooled = out.mean(dim=1)         # [B, d_model]

                # 5) å›å½’è¾“å‡º
                pred = self.regressor(pooled)    # [B, 1]
                return pred.squeeze(-1)          # [B]    
        return WithBiasConvTransformerRegressor()
    def load_trained_model(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        if os.path.exists(self.MODEL_SAVE_PATH):
            self.model = self._create_model()
            self.model.load_state_dict(torch.load(self.MODEL_SAVE_PATH))
            self.model.to(self.DEVICE)
            self.model.eval()
            if self.details:
                print(f"âœ… å·²åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {self.MODEL_SAVE_PATH}")
        else:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {self.MODEL_SAVE_PATH}")
    
    def train(self):
        """è®­ç»ƒæƒ…æ„Ÿå›å½’æ¨¡å‹"""
        if self.type != "train":
            raise ValueError("æ¨¡å‹æœªé…ç½®ä¸ºè®­ç»ƒæ¨¡å¼")
        
        if self.details:
            print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        
        best_val_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(self.EPOCHS):
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            train_loss = 0.0
            
            with tqdm(total=len(self.train_loader), desc=f"Epoch {epoch+1}/{self.EPOCHS}") as pbar:
                for features, labels in self.train_loader:
                    features = features.to(self.DEVICE)
                    labels = labels.to(self.DEVICE)
                    
                    self.optimizer.zero_grad()
                    outputs = self.model(features).squeeze()
                    loss = self.criterion(outputs, labels)
                    loss.backward()
                    self.optimizer.step()
                    
                    train_loss += loss.item()
                    pbar.update(1)
                    pbar.set_postfix({"Train Loss": f"{loss.item():.4f}"})
            
            # éªŒè¯é˜¶æ®µ
            self.model.eval()
            val_loss = 0.0
            
            with tqdm(total=len(self.valid_loader), desc="Validation") as pbar:
                with torch.no_grad():
                    for features, labels in self.valid_loader:
                        features = features.to(self.DEVICE)
                        labels = labels.to(self.DEVICE)
                        
                        outputs = self.model(features).squeeze()
                        loss = self.criterion(outputs, labels)
                        val_loss += loss.item()
                        pbar.update(1)
                        pbar.set_postfix({"Val Loss": f"{loss.item():.4f}"})
            
            # è®¡ç®—å¹³å‡æŸå¤±
            train_loss /= len(self.train_loader)
            val_loss /= len(self.valid_loader)
            
            # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
            self.scheduler.step(val_loss)  # ä¼ å…¥éªŒè¯æŸå¤±ä»¥è°ƒæ•´å­¦ä¹ ç‡
            
            # æ‰“å°è®­ç»ƒè¿›åº¦ï¼ˆåŒ…å«å½“å‰å­¦ä¹ ç‡ï¼‰
            current_lr = self.optimizer.param_groups[0]['lr']
            if self.details:
                print(f"\nEpoch {epoch+1}/{self.EPOCHS} - "
                      f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {current_lr:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save(self.model.state_dict(), self.MODEL_SAVE_PATH)
                patience_counter = 0
                if self.details:
                    print(f"âœ… æ¨¡å‹ä¿å­˜: éªŒè¯æŸå¤±æ”¹å–„ ({best_val_loss:.4f})")
            else:
                patience_counter += 1
                if patience_counter >= self.PATIENCE:
                    if self.details:
                        print(f"ğŸ›‘ æ—©åœ: éªŒè¯æŸå¤±åœ¨{self.PATIENCE}ä¸ªå‘¨æœŸå†…æœªæ”¹å–„")
                    break
        
        if self.details:
            print(f"è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
            print(f"æœ€ç»ˆå­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
    


    def test_model(self):
        """åŠ è½½æ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œè¯„ä¼°"""
        if self.type != "load":
            self.load_trained_model()  # è‡ªåŠ¨åˆ‡æ¢ä¸ºåŠ è½½æ¨¡å¼
        
        # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        self.model.eval()
        # criterion = SpecialSomoothL1Loss()
        
        # åˆå§‹åŒ–è¯„ä¼°æŒ‡æ ‡
        total_loss = 0.0
        all_predictions = []
        all_labels = []
        
        # è¿›åº¦æ¡æ˜¾ç¤º
        progress = tqdm(self.test_loader, desc="Testing", unit="batch")
        with torch.no_grad():
            for features, labels in progress:
                features = features.to(self.DEVICE)
                labels = labels.to(self.DEVICE)
                
                # æ¨¡å‹é¢„æµ‹
                outputs = self.model(features).squeeze()
                # loss = criterion(outputs, labels).item()
                # total_loss += loss * len(labels)
                
                # æ”¶é›†ç»“æœ
                all_predictions.extend(outputs.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        # è®¡ç®—è¿ç»­æŒ‡æ ‡
        # avg_loss = total_loss / len(self.test_dataset)
        mse = mean_squared_error(all_labels, all_predictions)
        rmse = np.sqrt(mse)
        discrete_labels = [self.discretize(l) for l in all_labels]
        discrete_predictions = [self.discretize(s) for s in all_predictions]
        
        evaluation = self.evaluate(y_true=discrete_labels, y_pred=discrete_predictions)
        acc5 = evaluation["ACC5"]
        acc2 = evaluation["ACC2"]
        f1 = evaluation["F1"]
        
        # è®¡ç®—åˆ†ç±»æŒ‡æ ‡
        
        # æ‰“å°ç»“æœ
        print("\n================= æµ‹è¯•é›†è¯„ä¼°ç»“æœ =================")
        print(f"å¹³å‡æŸå¤± (MSE): {mse:.4f}")
        print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")
        print(f"äº”åˆ†ç±»å‡†ç¡®ç‡ (ACC5): {acc5:.4f}")
        print(f"äºŒåˆ†ç±»å‡†ç¡®ç‡ (ACC2): {acc2:.4f}")
        print(f"F1åˆ†æ•°: {f1:.4f}")
        print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(all_labels)}")
        print("================================================\n")
        
        

        return {
            "mse": mse,
            "rmse": rmse,
            "acc5": acc5,
            "acc2": acc2,
            "sample_count": len(all_labels)
        }
    
    
    def predict(self, video_path, openface_exe_path):
        """
        å¯¹ç»™å®šçš„è§†é¢‘è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹
        
        å‚æ•°:
            video_path (str): è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
            openface_exe_path (str): OpenFaceå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            Dict[str, Any]: åŒ…å«æƒ…æ„Ÿé¢„æµ‹ç»“æœçš„å­—å…¸
        """
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if self.type != "load" or not hasattr(self, 'model') or self.model is None:
            self.load_trained_model()
        
        self.model.eval()

        if not openface_exe_path or not os.path.exists(openface_exe_path):
            raise FileNotFoundError(f"OpenFaceå¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨: {openface_exe_path}")

        with tempfile.TemporaryDirectory() as temp_dir:
            # Step 1: ä½¿ç”¨ OpenFace æå–ç‰¹å¾
            print(f"ğŸ“¹ æ­£åœ¨å¤„ç†è§†é¢‘: {video_path}")
            video_processor = VideosProcessor(openface_exe_path)
            success_count = video_processor.process_videos(
                input_path=video_path,
                output_dir=temp_dir
            )
            if success_count == 0:
                raise RuntimeError("âŒ æ— æ³•å¤„ç†è§†é¢‘æˆ–æœªç”Ÿæˆæœ‰æ•ˆç‰¹å¾")

            # Step 2: æå–å’Œå½’ä¸€åŒ–ç‰¹å¾
            print("ğŸ§ª æ­£åœ¨æå–å’Œå½’ä¸€åŒ–ç‰¹å¾...")
            features = video_processor.extract_and_normalize_features(
                csv_folder=temp_dir,
                output_pkl_path=os.path.join(temp_dir, "features.pkl")
            )

            # Step 3: é¢„å¤„ç†ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
            video_id = os.path.splitext(os.path.basename(video_path))[0]
            if video_id not in features["videos"]:
                raise RuntimeError(f"âš ï¸ æœªæ‰¾åˆ°è§†é¢‘ {video_id} çš„æœ‰æ•ˆç‰¹å¾")

            vision_features = features["videos"][video_id]["vision"]  # shape: [T, D]
            vision_features = np.array(vision_features)

            # å¯¹å¸§æ•°è¿›è¡Œè£å‰ªæˆ–å¡«å……
            num_frames = self.NUM_FRAMES
            if vision_features.shape[0] >= num_frames:
                vision_features = vision_features[:num_frames]
            else:
                pad_len = num_frames - vision_features.shape[0]
                pad = np.zeros((pad_len, vision_features.shape[1]))
                vision_features = np.concatenate((vision_features, pad), axis=0)

            input_tensor = torch.tensor(vision_features, dtype=torch.float32).unsqueeze(0).to(self.DEVICE)  # shape: [1, T, D]

            # Step 4: æƒ…æ„Ÿé¢„æµ‹
            with torch.no_grad():
                output = self.model(input_tensor).squeeze().item()  # å•ä¸ªæ ‡é‡
                discrete_output = self.discretize(output)

            # Step 5: è¿”å›ç»“æœ
            return {
                "continuous": round(output, 4),
                "discrete_label": self.score_to_label(discrete_output),
                "discrete_value": discrete_output  
            }

    def discretize(self, value):
        """å°†è¿ç»­å€¼ç¦»æ•£åŒ–ä¸ºé¢„å®šä¹‰çš„ç¦»æ•£å€¼"""
        values = np.array(self.DISCRETE_VALUES)
        return  float(values[np.argmin(np.abs(values - value))]) 

        
    def score_to_label(self,score: float) -> str:
        TOLERANCE = 1e-6
        def is_close(a, b):
            return abs(a - b) < TOLERANCE
        if is_close(score, -1.0) or is_close(score, -0.8):
            return 'è´Ÿ'
        elif is_close(score, -0.6) or is_close(score, -0.4) or is_close(score, -0.2):
            return 'å¼±è´Ÿ'
        elif is_close(score, 0.0):
            return 'ä¸­'
        elif is_close(score, 0.2) or is_close(score, 0.4) or is_close(score, 0.6):
            return 'å¼±æ­£'
        elif is_close(score, 0.8) or is_close(score, 1.0):
            return 'æ­£'
        else:
            raise ValueError(f"Unexpected sentiment score: {score}")
        
    def label_to_acc2(self,label: str) -> int:
    # è´Ÿ/å¼±è´Ÿ -> 0, ä¸­/å¼±æ­£/æ­£ -> 1
        return 0 if label in ['è´Ÿ', 'å¼±è´Ÿ'] else 1

    def evaluate(self,y_true, y_pred):
        # è½¬ä¸º5ç±»æ ‡ç­¾
        y_true_5 = [self.score_to_label(s) for s in y_true]
        y_pred_5 = [self.score_to_label(s) for s in y_pred]
        # ACC5
        acc5 = accuracy_score(y_true_5, y_pred_5)
        # ACC2
        y_true_2 = [self.label_to_acc2(l) for l in y_true_5]
        y_pred_2 = [self.label_to_acc2(l) for l in y_pred_5]
        acc2 = accuracy_score(y_true_2, y_pred_2)
        # F1 (macro, 5ç±»)
        f1 = f1_score(y_true_5, y_pred_5, average='macro', labels=['è´Ÿ','å¼±è´Ÿ','ä¸­','å¼±æ­£','æ­£'])


        self.plot_discrete_histogram(y_pred, y_true)
        
        return {'ACC5': acc5, 'ACC2': acc2, 'F1': f1}
    
    def plot_discrete_histogram(self, y_pred, y_true):
        # ç»Ÿè®¡æ¯ä¸ªç¦»æ•£å€¼åœ¨é¢„æµ‹å€¼å’ŒçœŸå®æ ‡ç­¾ä¸­å‡ºç°çš„æ¬¡æ•°
        import matplotlib.pyplot as plt

        discrete_values = self.DISCRETE_VALUES
        from collections import Counter

        # ç»Ÿè®¡é¢‘ç‡
        pred_counts = Counter(y_pred)
        true_counts = Counter(y_true)

        # æ„é€ å®Œæ•´çš„é¢‘ç‡æ•°ç»„
        x = np.array(discrete_values)
        pred_freq = np.array([pred_counts.get(val, 0) for val in x])
        true_freq = np.array([true_counts.get(val, 0) for val in x])

        # æŸ±å®½ä¸ä½ç½®
        bar_width = 0.08
        x_indices = np.arange(len(x))

        # ç»˜å›¾
        plt.figure(figsize=(10, 5))
        plt.bar(x_indices - bar_width/2, true_freq, width=bar_width, label='True Labels', color='orange')
        plt.bar(x_indices + bar_width/2, pred_freq, width=bar_width, label='Predicted Values', color='blue')

        # è®¾ç½®åˆ»åº¦å’Œæ ‡ç­¾
        plt.xticks(ticks=x_indices, labels=[f'{v:.1f}' for v in x])
        plt.xlabel('Discrete Value')
        plt.ylabel('Frequency')
        plt.title('Distribution of Discretized Predicted Values and True Labels')
        plt.legend()
        plt.grid(True, linestyle='--', alpha=0.6)
        plt.tight_layout()
        plt.show()